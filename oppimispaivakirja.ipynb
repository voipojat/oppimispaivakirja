{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JODA-oppimispäiväkirja\n",
    "\n",
    "# Anton Tuominen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#    Viikko 1 - Mitä on datatiede?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Osallistuin ensimmäisen viikon opetukseen hieman jälkijunassa työkiireiden vuoksi. Hyödynsin päiväkirjan laatimisessa luentovideota sekä luennon Jupyter-notebookkia.\n",
    "\n",
    "Tällä luentoviikolla käsiteltiin datatieteen määritelmää ja siihen liittyviä työvälineitä. Datatiede itsessään ei ole yhden tekijän summa, vaan se rakentuu erilaisista kokonaisuuksista: liiketoimintaosaamisesta, ohjelmointi – ja tietokantaosaamisesta, tilastollisesta analyysista sekä datalähtöisestä viestinnästä ja visualisoinnista. \n",
    "\n",
    "Datatieteen kehityksessä avainasemassa olivat kehittyneet kehitystyökalut sekä laskentatehon kasvaminen. Iso muutos oli, kun R -ohjelmointiympäristöstä siirryttiin Pythoniin. Toisin sanoen tilastolliseen laskentaan ja grafiikan tuottamiseen voitiin nyt myös yhdistää Pythonin kautta koneoppiminen. \n",
    "\n",
    "Luennolla käsiteltiin myös datan eettisyyteen liittyviä ihmisoikeuskysymyksiä; kenellä on pääsy tähän dataan? Nykypäivänä monet internet-sivut pyytävät käyttäjää hyväksymään evästeet, ennen kuin sivulla voi tehdä mitään. Nämä evästeet keräävät käyttäjästä valtavasti dataa. Esimerkiksi verkkokaupassa tekemä ostos saa aikaan sen, että käyttäjä näkee mainoksia eri sivuilla viimeisimmän ostoksensa kauppapaikasta. Tämä tapahtuu usein niin, että kauppapaikan omistaja maksaa Googlelle mainoksen näyttämisestä.\n",
    "\n",
    "**Viisi oivallusta**\n",
    "* Datatiede rakentuu neljästä laajasta kokonaisuudesta\n",
    "* 80% Data Scientistin ajasta kuluu datan siivoamiseen\n",
    "* Laskentateho on kasvanut valtavasti 1970-luvulta tähän päivään\n",
    "* Algoritmeilla voidaan ohjata monien elämää\n",
    "* Datafikaatio haastaa ihmisten yksityisyyden\n",
    "\n",
    "**Kehityskohde**: Kehitysympäristöjen käytöstä ja asentamisesta olisi voinut ehkä olla enemmän ohjeistusta. \n",
    "\n",
    "**Koodiesimerkki**: Käytin koodiesimerkin tekemisessä apuna ensimmäistä demosessiota. Tavoitteena koodissa on muuttaa haluttujen attribuuttien datatyyppejä."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = 'https://github.com/jodatut/2020/raw/master/koodiesimerkit/SalesJan2009.csv'\n",
    "\n",
    "# Käytetään pandas-kirjastoa datan lukemiseen\n",
    "orig_df = pd.read_csv(url)\n",
    "\n",
    "df = orig_df.copy()\n",
    "print('List of attributes:', df.columns.values.tolist())\n",
    "\n",
    "print(df.head())\n",
    "print(df.dtypes)\n",
    "# Muutetaan attribuuttien datatyypit\n",
    "df['Transaction_date'] = pd.to_datetime(df['Transaction_date'])\n",
    "df['Account_Created'] = pd.to_datetime(df['Account_Created'])\n",
    "df['Last_Login'] = pd.to_datetime(df['Last_Login'])\n",
    "\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viikko 2 - Datan kerääminen ja jalostaminen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Osallistuin toisen luentoviikon opetukseen katsomalla luentovideon jälkikäteen. Hyödynsin päiväkirjan laatimisessa luentovideota, luennon Jupyter-notebookkia sekä artikkelia asiakaspoistuma-analyysista (https://bilot.group/articles/asiakaspoistuma-analyysi-ja-miljoona-lisamyyntia/).\n",
    "\n",
    "Tällä luentoviikolla käsiteltiin datatieteen työprosessia, data-analytiikan liiketoimintarelevanssia, datan keruun menetelmiä sekä datan muotoja.\n",
    "\n",
    "Philip Guon mukaan datatieteen työprosessi koostuu neljästä päävaiheesta: datan esikäsittelystä (kerääminen, siivoaminen, jalostaminen), analyysin ja tulosten vertailusta ja sekä lopuksi tulosten esittämisestä sopivassa muodossa vastaanottajalle.  \n",
    "\n",
    "Liiketoimintarelevanssin kannalta data-analytiikka on avainasemassa, kun katsotaan yrityksen suorituskykyä. Bilot Groupin artikkelissa käydään läpi, miten asiakaspoistuma-analyysi voi olla hyvinkin tuottoisa yritykselle. Pieni investointi analyysiin voi johtaa huimiin tuottoihin, jos analyysin tulosten perusteella asiakkaiden poistumaa voidaan pudottaa. Artikkelin mukaan yllättävän harva yritys hyödyntää asiakaspoistuma-analyysia. Syyt tähän voivat johtua tietämättömyydestä tai itsepetoksesta; ei kuvitella, että asiakkaan lähtöön vaikuttaisi mikään muu kuin tuotteen hinta. \n",
    "\n",
    "**Viisi oivallusta**\n",
    "*\tData-analytiikka on liiketoiminnan kannalta hyvinkin relevantti asia\n",
    "*\tRyömijän tarkoituksena on yleisesti sivujen indeksointi\n",
    "*\tRaapija hyödyntää sivuston metaelementtejä käyttäjää kiinnostavan tiedon tallentamiseen\n",
    "*\tDatainsinöörit keskittyvät dataan liittyviin algoritmeihin, arkkitehtuuriin sekä pitävät huolen siitä, että data kulkee vaivattomasti lähteen ja määränpään välillä \n",
    "*\tDatatieteilijät keskittyvät enemmän tilastolliseen analyysiin saadusta datasta\n",
    " \n",
    "**Kehityskohde:** Analytiikkatyypeistä olisi ehkä voinut olla enemmän esimerkkejä\n",
    "\n",
    "**Koodiesimerkki:** Luentoviikolla käsiteltiin raapijoita, joten päätin tehdä yksinkertaisen RedditSpiderin, joka    Scrappya hyödyntäen hakee etusivun postauksien otsikoita.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "\n",
    "class RedditSpider(scrapy.Spider):\n",
    "    name = \"reddit\"\n",
    "    start_urls = ['https://www.reddit.com/']\n",
    "\n",
    "    def parse(self, response):\n",
    "        for title in response.css('h3'):\n",
    "\n",
    "            yield {\n",
    "                'title': title.css('::text').extract()\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viikko 3 - Koneoppimisen periaatteet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Osallistuin kolmannen viikon opetukseen katsomalla luentovideon jälkikäteen. Hyödynsin päiväkirjan laatimisessa luentovideota sekä luennon Jupyter-notebookkia.\n",
    "\n",
    "Tällä luentoviikolla käsiteltiin koneoppimisen periaatteita, piirteiden suunnittelua sekä yhtä koneoppimisalgoritmien tyyppiä, ohjattua oppimista.\n",
    "\n",
    "Ohjatussa oppimisessa algoritmia opetetaan valmiiksi luokitellulla opetusdatalla. Tämä piirteiden (ennustavien muuttujien) erottelu raakadatasta on voitu tehdä joko automatisoidusti tai piirteet on voitu kehitellä ja suunnitella asiantuntijatyönä. \n",
    "Piirteiden erottelun jälkeen voidaan laatia piirrematriisi; sarakkeet piirteitä, rivit yksittäisiä havaintoja. Tässä vaiheessa siirrytään varsinaiseen opetusvaiheeseen, jonka seurauksena muodostuu malli, jota käyttäen voidaan ennustaa haluttua asiaa.\n",
    " \n",
    "Käytännön esimerkki voisi olla mobiilioperaattorin asiakaspoistuma-analyysi, jonka avulla halutaan ennustaa, kuka asiakkaista tulee todennäköisesti poistumaan. Opetusdatana toimii esimerkiksi asiakkaiden henkilötiedot ja tilaukset sekä tieto siitä, kuka on poistunut ja kuka ei. Tämä data käsitellään ja kehitetään algoritmi, johon voidaan syöttää uutta dataa, ja näin saadaan ennustuksia asiakkaiden poistumistodennäköisyyksistä. \n",
    "\n",
    "Isoin aika tällaisten mallien kehittelyssä menee piirteiden suunnitteluun ja jalostukseen, jos piirteitä ei erotella automatisoidusti. ”Feature engineering” on olennainen osa koneoppimisen kehitystyötä, eräänlainen taiteenlaji. Asiantuntijuudella aineistosta voidaan alkaa tuottamaan laadukkaita piirteitä, jotka soveltuvat hyvin koneoppimistehtävään. Toisin sanoen kokemuksella pystyy vaikuttamaan algoritmin suorituskykyyn merkittävästi. \n",
    "\n",
    "**Viisi oivallusta**\n",
    "*   Algoritmia voidaan parantaa piirteitä jalostamalla\n",
    "*\tKun toimitaan ei-teknisten ihmisten kanssa, on tärkeää, että algoritmi on yksinkertainen ja ymmärrettävä\n",
    "*\tFeature engineering olennainen osa koneoppimisen kehitystyötä\n",
    "*\tKoneoppimismallien ennustuskyky on parantunut merkittävästi, mutta mallien yksityiskohdat eivät aina avaudu ihmistulkitsijalle\n",
    "*\tOpetusdatasetit ovat tekoälyajan tärkein resurssi\n",
    "\n",
    "**Kehityskohde:** Luentojen esitysmateriaalin rakenteeseen voisi tehdä muutoksia, sillä se on toisinaan raskasta luettavaa pitkien koodi-outputtien takia.\n",
    "\n",
    "**Koodiesimerkki** Päätin hyödyntää kolmannen demosession oppeja, ja poistin piirteitä Airbnb-asuntojen datasetistä sekä siivosin sitä. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.impute import SimpleImputer as Imputer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv(\"listings.csv\")\n",
    "# Poistetaan kolme piirrettä\n",
    "cols_to_remove = ['listing_url', 'scrape_id', 'last_scraped']\n",
    "data = df.drop(cols_to_remove, axis=1)\n",
    "\n",
    "# Korvataan tyhjät arvot sarakkeen keskiarvolla\n",
    "cols_to_clean =['review_scores_location', 'reviews_per_month']\n",
    "\n",
    "imputer = Imputer()\n",
    "data[cols_to_clean] = imputer.fit_transform(data[cols_to_clean])\n",
    "data[cols_to_clean] = data[cols_to_clean].astype(int)\n",
    "# Poistetaan kaikki rivit, joilla on vielä ainakin yksi NaN arvo\n",
    "data.dropna()\n",
    "\n",
    "data.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viikko 4 – Harjoitustyöhön tutustuminen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Osallistuin neljännen luentoviikon opetukseen katsomalla luentovideon jälkikäteen. Hyödynsin päiväkirjan laatimisessa luentovideota sekä luennon Jupyter-notebookkia.\n",
    "\n",
    "Tällä luentoviikolla käsiteltiin kurssin harjoitustyötä, CRISP-DM -prosessia sekä Jeff Pattonin esittelemää mahdollisuuskehikkoa.\n",
    "\n",
    "Mahdollisuuskehikko on kehitetty liiketoiminta- ja Lean -kehikkojen hengessä. Kehikon ideana on  keskustelun mahdollistaminen ideoinnin alla olevasta ratkaisusta. Keskustelun teemoina ovat mm. ratkaisun käyttötarkoitus, nykypäivänä olemassa olevat ratkaisut sekä ratkaisun vaikutukset yrityksen liiketoimintaan. \n",
    "\n",
    "Dataprojektin aloituksessa on tärkeää, että lähtökohtana on jonkinlainen liiketoimintaongelma, jonka ratkaiseminen tuottaisi arvoa itse liiketoimintaprosessille. Omassa harjoitustyössäni tutkin kurssilla annettua templaatti-ongelmaa, eli Airbnb-asunnon hintaan vaikuttavia tekijöitä.  Tällainen tutkimus toisi luonnollisesti lisäarvoa Airbnb-asunnon omistajalle, sillä hänelle voisi kertoa erilaisia tutkimuksessa löytyneitä tekijöitä, jotka korreloivat asunnon hinnan kanssa. Muun muassa tiedot vuokraajan vastausaktiivisuudesta sekä asunnon sijainnista voisivat olla tällaisia tekijöitä.\n",
    "\n",
    "Kun projektin liiketoiminnan kannalta relevantti tutkimusongelma on päätetty, on CRISP-DM -prosessin seuraavien vaiheiden aika. Näihin vaiheisiin kuuluu datan kerääminen, datan ymmärtäminen ja sen jalostaminen sekä datan visualisointi ja sen mallinnuksesta tehtävät päätelmät. Prosessi on luonteeltaan iteroiva, eli vaiheesta voidaan hypätä taaksepäin edelliseen vaiheeseen ennen virallista lopputulosta. Tällainen iterointi on hyvin tärkeää, sillä matkan varrella herää varmasti uusia oivalluksia esim. siitä, miten dataa olisi voinut rikastaa paremmin, kun on syntynyt parempi kokonaiskuva datasta sekä koko prosessista. \n",
    "\n",
    "**Viisi oivallusta**\n",
    "*\tDatatiedeprojektissa lähtökohtana on liiketoimintaongelma, ei data\n",
    "*\tDatatiedeprojektit ovat luonteeltaan iteratiivisia \n",
    "*\tMahdollisuuskehikko kätevä työkalu, kun tarvitaan vastauksia olennaisiin kysymyksiin\n",
    "*\tDatan visualisointi ei itsessään tuota minkäänlaista lisäarvoa, ellei pysty selittämään miksi juuri kyseinen kuvaaja on arvokas asiaa analysoivalle taholle\n",
    "*\tIteroitaessa voi syntyä paljon uusia ideoita ja kysymyksiä projektiin liittyen \n",
    "\n",
    "**Kehityskohde:** Breakout -roomit ja Flinga jäävät hieman turhiksi, jos liveluennolla ei ole paljon porukkaa\n",
    "\n",
    "**Koodiesimerkki:** Päätin hyödyntää koodiesimerkissä harjoitustyössänikin olevaa koodinpätkää, joka liittyy datan siivoamiseen.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3679 rows where there values for 'reviews_per_month'\n",
    "# are null, let's fix this by changing the nulls to 0\n",
    "df['reviews_per_month'].fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "# At this point we can drop rows\n",
    "# with bad values \n",
    "df = df[df.bedrooms != 0]\n",
    "df = df[df.price != 0]\n",
    "df = df.dropna(axis=0)\n",
    "\n",
    "print(df.isnull().sum())\n",
    "print(len(df.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viikko 5 – Solitan vierailuluento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Osallistuin neljännen luentoviikon opetukseen katsomalla luentovideon jälkikäteen. Hyödynsin päiväkirjan laatimisessa luentovideota sekä luennon Jupyter-notebookkia.\n",
    "\n",
    "Tämän viikon luento poikkesi aiemmista luennoista, sillä kyseessä oli JODA-kurssin ensimmäinen vierailuluento. Vierailijoina toimivat Solitan Teemu Mikkonen (Data engineer) ja Timo Lehtonen (ohjelmistokehittäjä).\n",
    "\n",
    "Luennolla käsiteltiin NLP:tä (Natural Language Processing) ja kyseisen menetelmän hyödyntämistä eduskuntadatan luokittelussa. NLP:n avulla pystymme erottamaan informaatiota (piirteet) luonnollisesta kielestä ja muuttamaan sen numeeriseen muotoon. NLP on usein linkitetty johonkin data/koneoppimisratkaisuun, sillä NLP:n avulla tehty piirteiden erotus voi tuoda uuden ulottuvuuden koneoppimisratkaisussa käytettyyn opetusdataan. \n",
    "\n",
    "NLP:tä hyödynnettiin luennon esimerkissä siten, että eduskuntadatasta saatujen datapisteiden (ministerien vastaukset kirjallisiin kysymyksiin) luokitteluun. Toisin sanoen koneoppimismenetelmää hyödyntämällä haluttiin kehittää malli, joka ennustaisi todennäköisyyttä siihen, mihinkä ”ministeri-salkku” -luokkaan esimerkiksi ministerin twiitti kuuluisi. \n",
    "\n",
    "**Viisi oivallusta**\n",
    "*\tOpetusdataa voidaan esikäsitellä sekä ennen mallin opettamista että mallin opetusfunktion sisällä\n",
    "*\tVerkkokauppojen chatbotit hyödyntävät NLP:tä\n",
    "*\tYliotannan ideana on luoda datasettiin keinotekoisia arvoja, jotka ovat lähellä tunnisteen datapisteitä\n",
    "*\tFastText on kevyt NLP-kirjasto, joka on helppo ottaa käyttöön, mutta se ei ole läheskään yhtä kehittynyt kuin esimerkiksi ULMFiT ja BERT\n",
    "*\tSolitan Data Akatemia kuulostaa mielenkiintoiselta startilta datatiedeuralle\n",
    "\n",
    "**Kehityskohde:** Mielestäni vierailuluento oli hyvin toteutettu, sillä se mahdollisti myös katsojien osallistamisen aiheeseen ajettavan koodin avulla. Ei kehitysideoita.\n",
    "\n",
    "**Koodiesimerkki:** Päätin ottaa koodiesimerkiksi luennolla esitellyn koodinpätkän, jossa muutetaan sana sen perusmuotoon Voikkoa hyödyntämällä. Esimerkiksi sanasta \"Yliopistojen\" tulisi \"yliopisto\". Ajoin kyseistä koodia vain Colabin puolella, joten tarvittavat ennakkotoimeenpiteet (muuttujien alustus, importit) puuttuvat tästä pätkästä.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseform_words = []\n",
    "\n",
    "for word in words:\n",
    "  if type(word) != None:\n",
    "    #Voikon analyze-metodi muuttaa sanan sen perusmuotoon\n",
    "    voikko_dict = v.analyze(word)\n",
    "    if voikko_dict:\n",
    "      word = voikko_dict[0]['BASEFORM']\n",
    "      if word not in stopwords:\n",
    "        baseform_words.append(word)\n",
    "\n",
    "text_bf = \" \".join(baseform_words)\n",
    "print(\"Alkuperäinen:\", \"\\n\", text, \"\\n\")\n",
    "print(\"Perusmuotoinen:\", \"\\n\", text_bf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viikko 6 – Ohjaamaton koneoppiminen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Osallistuin neljännen luentoviikon opetukseen katsomalla luentovideon jälkikäteen. Hyödynsin päiväkirjan laatimisessa luentovideota sekä luennon Jupyter-notebookkia. Tällä luentoviikolla käsiteltiin ohjaamatonta oppimista sekä sen menetelmiä, mm. ryvästämistä sekä aihemallinnusta. \n",
    "\n",
    "Ohjaamattomassa oppimisessa ideana on pyrkimys kuvaamaan aineiston rakennetta oppimalla jokin aineistoon sopiva malli. Isoin eroavaisuus ohjattuun oppimiseen on se, että ei pyritä ennustamaan piirteitä, vaan pikemminkin kuvaamaan aineiston rakennetta.\n",
    "\n",
    "Ryvästäminen on yksi ohjaamattoman oppimisen menetelmä, jossa lähtödata jaetaan ryppäisiin, jotka ovat keskenään mahdollisimman samankaltaisia, mutta mahdollisimman etäällä toisistaan.  Keskeistä on siis löytää keskenään samankaltaisia havaintoja datasta. KMeans -algoritmit ovat esimerkki ryvästämisestä; ne perustuvat iteratiiviseen klustereiden perusteella tapahtuvaan keskipisteiden laskemiseen. \n",
    "\n",
    "Aihemallinnus on myös eräs ohjaamattoman oppimisen menetelmä, joka mahdollistaa laajojen tekstiaineistojen automaattisen ryhmittelyn. Ideana on tekstiaineistossa esiintyvien abstraktien aiheiden löytäminen; pyritään löytämään piilotetut semanttiset rakenteet. Luonteeltaan aihemallinnus on tietyllä tapaa subjektiivista, jossa piileekin vaaran paikka, nimittäin aiheiden määrän (k) valinnalla on suuri vaikutus lopputulokseen.\n",
    "\n",
    "**Viisi oivallusta**\n",
    "*\tOhjaamattomassa oppimisessa tapahtuu myös ohjaamista (esim. aiheiden määrän valinta)\n",
    "*\tAihemallinnuksessa aiheiden määrän valinnalla suuri merkitys lopputuloksen kannalta\n",
    "*\tKyynärpääperiaate mielenkiintoinen lähetymistapa klustereiden määrän valintaan\n",
    "*\tKMeans -algoritmia käytettäessä outlier -havainnoilla merkittävä vaikutus tulokseen\n",
    "*\tGensim -kirjasto oiva työkalu semanttiseen analyysiin\n",
    "\n",
    "**Kehityskohde:** Ostoskorianalyysia olisi voinut avata enemmän.\n",
    "\n",
    "**Koodiesimerkki:** Päätin hyödyntää koodiesimerkissä luennolla esiteltyä esimerkkiä liittyen aihemallinnukseen. Oheisessa koodissa tulostetaan piilevistä 3 teemasta 10 todennäköisintä sanaa. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_terms = lda.show_topics(num_topics=int(n_topics), num_words=11, log=False, formatted=False)\n",
    "index = 0\n",
    "topTerms={}\n",
    "for topic in range(n_topics):\n",
    "    for wordn in range(11):\n",
    "        try:\n",
    "            topTerms['Topic '+str(topic+1)].append(temp_terms[topic][1][wordn][0])\n",
    "        except KeyError:\n",
    "            topTerms['Topic '+str(topic+1)]=[temp_terms[topic][1][wordn][0]]\n",
    "ldaTermsDf=pd.DataFrame(topTerms)\n",
    "ldaTermsDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viikko 7 – Visuaalinen analytiikka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Osallistuin neljännen luentoviikon opetukseen katsomalla luentovideon jälkikäteen. Hyödynsin päiväkirjan laatimisessa luentovideota sekä luennon Jupyter-notebookkia. Tällä luentoviikolla käsiteltiin visuaalisen analytiikan ja eksploratiivisen analytiikan hyödyntämistä datatieteen saralla. \n",
    "\n",
    "Visuaalisessa analytiikassa tuotetaan visuaalisia esityksiä aineistosta, jonka tavoitteena on auttaa analysoijaa ottaa vastaan informaatiota sekä tunnistamaan merkityksiä ja tekemään johtopäätöksiä esitetyn datan avulla. John Tukeyn (1980) mukaan visuaalinen analytiikka on pikemminkin lähestymistapa, eikä yksittäisiä tekniikoita.\n",
    "\n",
    "Datavisualisoinnin eräänä tavoitteena on auttaa loppukäyttäjää ymmärtämään aineistoa paremmin. Yleisenä sääntönä voidaan pitää sitä, että vähemmän on usein enemmän. Pyrin omassa harjoitustyössäni pitämään kaaviot ja kuvaajat mahdollisimman yksinkertaisina, jotta loppukäyttäjä saisi niistä enemmän irti. Tavoitteenani oli myös olennaisten asioiden kuvaaminen. \n",
    "\n",
    "**Viisi oivallusta** \n",
    "*\tVisualisoinnilla kaksi keskeistä sovellusta datatieteessä (kartoittava analytiikka sekä kommunikointi)\n",
    "*\tBen Fryn esittelemät seitsemän askelta datan visualisoinnille \n",
    "*\tVisualisoinnin asettelu on tärkeässä asemassa ymmärrettävyyden kannalta\n",
    "*\tVähemmän on enemmän -> pyritään kuvaamaan olennaiset asiat\n",
    "*\tVisualisoinnin suunnittelu edellyttää laajaa osaamista ihmisen ja koneen vuorovaikutuksesta visualisointijärjestelmien tekniseen arkkitehtuuriin\n",
    "\n",
    "**Kehityskohde:** Ei mitään kehityskohdetta, luentomateriaalin lisäksi oli tarjolla paljon linkkejä muihin tietolähteisiin mikä oli hieno juttu.\n",
    "\n",
    "**Koodiesimerkki:**  Päätin hyödyntää koodiesimerkissä harjoitustyössänikin olevaa koodia, jossa visualisoin Airbnb-asunnon hinnan sekä majoittujien välistä lineearista regressiota matplotlibin avulla.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = linear_model.LinearRegression()\n",
    "x = df['accommodates'].values[:, np.newaxis]\n",
    "y = df['price']\n",
    "clf = lr.fit(x, y)\n",
    "plt.scatter(x,y,color='red')\n",
    "plt.plot(x, clf.predict(x), color='black')\n",
    "plt.xlabel('accommodates')\n",
    "plt.ylabel('price')\n",
    "plt.ylim([0, 2000])\n",
    "plt.show"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
